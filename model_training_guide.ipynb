{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, you can use the **pre-split training, validation, and test sets** provided by the NSynth dataset to train, validate, and evaluate your model. These pre-split datasets ensure that there is no overlap in the instruments used between the training, validation, and test sets, which is critical for ensuring a model that generalizes well.\n",
    "\n",
    "The NSynth dataset provides data in two formats:\n",
    "1. **WAV/JSON**: A set of audio files (`.wav`) and corresponding metadata (`.json`).\n",
    "2. **TFRecord**: A TensorFlow-specific data format that can be used to efficiently train models in TensorFlow.\n",
    "\n",
    "Here, I'll guide you through both formats: loading the data, preprocessing it, training a model using the training set, validating on the validation set, and evaluating on the test set.\n",
    "\n",
    "### 1. **Using the WAV/JSON Files**\n",
    "\n",
    "The **WAV/JSON** format contains individual audio files along with a `JSON` file that holds metadata about each audio file, such as pitch, instrument family, and velocity. This approach is simpler if you're using non-TensorFlow environments or if you prefer handling individual audio files directly.\n",
    "\n",
    "#### A. **Load Training, Validation, and Test Data**\n",
    "\n",
    "Each dataset (`train`, `valid`, and `test`) has corresponding folders with the WAV audio files and metadata in JSON format.\n",
    "\n",
    "```python\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Paths to the different sets\n",
    "train_data_dir = 'path_to_nsynth_train'\n",
    "valid_data_dir = 'path_to_nsynth_valid'\n",
    "test_data_dir = 'path_to_nsynth_test'\n",
    "\n",
    "# Load metadata JSON for each set\n",
    "def load_metadata(data_dir):\n",
    "    metadata_path = os.path.join(data_dir, 'examples.json')\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    return metadata\n",
    "\n",
    "# Load the metadata for train, validation, and test\n",
    "train_metadata = load_metadata(train_data_dir)\n",
    "valid_metadata = load_metadata(valid_data_dir)\n",
    "test_metadata = load_metadata(test_data_dir)\n",
    "```\n",
    "\n",
    "#### B. **Preprocessing: Extract Features from Audio (Mel Spectrogram)**\n",
    "\n",
    "You’ll need to convert the raw audio data into features (e.g., Mel spectrograms) that the model can use. Here’s how to extract Mel spectrograms from the audio files:\n",
    "\n",
    "```python\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_mel_spectrogram(file_path, sr=16000, n_mels=128):\n",
    "    \"\"\"Extract Mel spectrogram from an audio file.\"\"\"\n",
    "    audio, _ = librosa.load(file_path, sr=sr)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    return mel_spectrogram_db\n",
    "\n",
    "# Extract Mel spectrograms and prepare labels\n",
    "def prepare_data(metadata, data_dir):\n",
    "    X, y = [], []\n",
    "    audio_dir = os.path.join(data_dir, 'audio')\n",
    "\n",
    "    for key, entry in metadata.items():\n",
    "        pitch = entry['pitch']  # Target label is the pitch\n",
    "\n",
    "        # Path to the audio file\n",
    "        audio_path = os.path.join(audio_dir, f\"{key}.wav\")\n",
    "        \n",
    "        # Extract Mel spectrogram\n",
    "        mel_spectrogram = extract_mel_spectrogram(audio_path)\n",
    "        \n",
    "        # Store the features and labels\n",
    "        X.append(mel_spectrogram)\n",
    "        y.append(pitch)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Reshape X to have the proper dimensions for CNN input\n",
    "    X = X[..., np.newaxis]\n",
    "    return X, y\n",
    "\n",
    "# Prepare train, valid, and test datasets\n",
    "X_train, y_train = prepare_data(train_metadata, train_data_dir)\n",
    "X_valid, y_valid = prepare_data(valid_metadata, valid_data_dir)\n",
    "X_test, y_test = prepare_data(test_metadata, test_data_dir)\n",
    "```\n",
    "\n",
    "#### C. **Train a Model**\n",
    "\n",
    "Once the data is preprocessed, you can train a **Convolutional Neural Network (CNN)** to predict the pitch (in MIDI format).\n",
    "\n",
    "```python\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_pitch_model(input_shape):\n",
    "    \"\"\"Build a CNN model for pitch prediction.\"\"\"\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Flatten and dense layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    \n",
    "    # Output layer for regression (predicting pitch in MIDI values)\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build and train the model\n",
    "input_shape = (128, X_train.shape[2], 1)\n",
    "model = build_pitch_model(input_shape)\n",
    "\n",
    "# Train the model on the training set\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_valid, y_valid))\n",
    "```\n",
    "\n",
    "#### D. **Evaluate the Model on the Test Set**\n",
    "\n",
    "After training, evaluate the model on the test set to see how well it generalizes to unseen data.\n",
    "\n",
    "```python\n",
    "# Evaluate on the test set\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test)\n",
    "print(f'Test MAE: {test_mae}')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Using the TFRecord Files**\n",
    "\n",
    "If you are using TensorFlow, the **TFRecord** format is a more efficient way to load and train on the NSynth data. It allows you to stream the data in batches directly into TensorFlow without needing to load it all into memory.\n",
    "\n",
    "#### A. **Loading TFRecord Files**\n",
    "\n",
    "NSynth provides the data in **TFRecord** format, which is optimized for TensorFlow. You can use TensorFlow’s `tf.data` API to load and preprocess this data efficiently.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# Path to the TFRecord files\n",
    "train_tfrecord_path = 'path_to_train.tfrecord'\n",
    "valid_tfrecord_path = 'path_to_valid.tfrecord'\n",
    "test_tfrecord_path = 'path_to_test.tfrecord'\n",
    "\n",
    "# Feature description dictionary for decoding the TFRecord\n",
    "feature_description = {\n",
    "    'audio': tf.io.FixedLenFeature([], tf.string),\n",
    "    'pitch': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "# Function to parse the TFRecord\n",
    "def _parse_function(proto):\n",
    "    parsed_features = tf.io.parse_single_example(proto, feature_description)\n",
    "    \n",
    "    # Decode the audio and cast the pitch label\n",
    "    audio = tf.audio.decode_wav(parsed_features['audio'])\n",
    "    pitch = tf.cast(parsed_features['pitch'], tf.int64)\n",
    "    \n",
    "    # Return the audio and pitch label\n",
    "    return audio, pitch\n",
    "\n",
    "# Load the datasets\n",
    "def load_dataset(tfrecord_path):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    return dataset\n",
    "\n",
    "train_dataset = load_dataset(train_tfrecord_path)\n",
    "valid_dataset = load_dataset(valid_tfrecord_path)\n",
    "test_dataset = load_dataset(test_tfrecord_path)\n",
    "```\n",
    "\n",
    "#### B. **Batching and Prefetching**\n",
    "\n",
    "Once you’ve loaded the TFRecord files, you can batch and prefetch the data to improve training performance.\n",
    "\n",
    "```python\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "```\n",
    "\n",
    "#### C. **Model Training and Evaluation**\n",
    "\n",
    "You can use the same model defined earlier for training and evaluation with the TFRecord datasets. Simply pass the `train_dataset` and `valid_dataset` to the `fit()` function:\n",
    "\n",
    "```python\n",
    "# Train the model on the TFRecord dataset\n",
    "history = model.fit(train_dataset, epochs=20, validation_data=valid_dataset)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_mae = model.evaluate(test_dataset)\n",
    "print(f'Test MAE: {test_mae}')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **WAV/JSON**: If you’re comfortable working with individual audio files, you can manually extract features (such as Mel spectrograms) from the WAV files and train your model.\n",
    "- **TFRecord**: This is a more TensorFlow-native format that allows for efficient streaming and training of large datasets. You can load the data using the `tf.data` API and train directly from the TFRecord files.\n",
    "\n",
    "In both cases, the pre-split training, validation, and test sets ensure that your model is trained, validated, and evaluated on non-overlapping sets of instruments, which is crucial for building a model that generalizes well."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
